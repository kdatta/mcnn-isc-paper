%!TEX root=main.tex
\begin{section}{Discussion} \label{sec:discussion}
	\noindent  In this work, we explored training a multi-scale convolutional neural network to classify large high content screening images within one hour by exploiting large memory in CPU systems. The cellular images used are over million pixels in resolution and are 26 times larger than those in the ImageNet dataset. We used two sets of cellular images with different resolutions to analyze the performance on multiple nodes of M-CNN training. The first set contains 10K full resolution cellular images (1024$\times$1280$\times$3) and the second dataset contains 313K images of smaller dimensions (724$\times$724$\times$3). With the first dataset, we were able to scale time to train linearly using 8X 2S Intel\textregistered{} Xeon\textregistered{} Gold processors. Large mini-batch sizes enabled by the large memory footprint in CPUs helped us achieve the speedup in training time. With the second data set, we were able to achieve TTT of 50 minutes, a 19.2X improvement in time to train using 128 Intel\textregistered{} Xeon\textregistered{} Gold processors. We learned that the updates per epoch is critical to achieve convergence and if the characteristics of the images in the dataset cannot tolerate scaling of updates per epoch beyond a certain threshold (2048 in our case), then adding more computational resources results in diminishing returns. In future work, we intend to explore larger datasets with more variation where images are chosen from different cohorts.
\end{section}
